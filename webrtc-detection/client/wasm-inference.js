// WASM-based Object Detection using ONNX Runtime Web
class WASMInference {
    constructor() {
        this.session = null;
        this.isLoaded = false;
        this.modelUrl = '/models/yolov5n.onnx'; // Make sure this path exists
        this.inputSize = 320; // Low-resource mode: 320x320
        this.isDebug = true; // Enable for debugging initially
        this.classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
            'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
            'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
            'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
            'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
            'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
            'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
            'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
            'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
        ];
    }

    async loadModel() {
        try {
            console.log('ðŸ§  Loading ONNX model for WASM inference...');
            console.log('ðŸ” Model URL:', this.modelUrl);

            // Check if model file exists first
            const modelCheck = await fetch(this.modelUrl, { method: 'HEAD' });
            if (!modelCheck.ok) {
                console.warn('âš ï¸ Model file not found at:', this.modelUrl);
                console.log('ðŸ“ Expected model location: public/models/yolov5n.onnx');
                console.log('ðŸ”„ Falling back to enhanced mock detections');
                this.isLoaded = false;
                return false;
            }

            // Import ONNX Runtime Web
            if (typeof ort === 'undefined') {
                console.log('ðŸ“¦ Loading ONNX Runtime Web...');
                await this.loadONNXRuntime();
            }

            // Configure ONNX Runtime for WASM
            ort.env.wasm.wasmPaths = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/';
            ort.env.wasm.numThreads = 1; // Low-resource mode
            ort.env.logLevel = 'warning';

            console.log('ðŸ“¥ Downloading model...');
            
            // Load the model
            this.session = await ort.InferenceSession.create(this.modelUrl, {
                executionProviders: ['wasm'],
                graphOptimizationLevel: 'all'
            });

            this.isLoaded = true;
            console.log('âœ… WASM model loaded successfully');
            console.log('ðŸ“Š Model inputs:', this.session.inputNames);
            console.log('ðŸ“Š Model outputs:', this.session.outputNames);
            return true;

        } catch (error) {
            console.error('âŒ Failed to load WASM model:', error);
            console.log('ðŸ”„ Falling back to enhanced mock detections...');
            this.isLoaded = false;
            return false;
        }
    }

    async loadONNXRuntime() {
        return new Promise((resolve, reject) => {
            const script = document.createElement('script');
            script.src = 'https://cdn.jsdelivr.net/npm/onnxruntime-web@1.19.0/dist/ort.min.js';
            script.onload = () => {
                console.log('âœ… ONNX Runtime Web loaded');
                resolve();
            };
            script.onerror = (error) => {
                console.error('âŒ Failed to load ONNX Runtime Web:', error);
                reject(error);
            };
            document.head.appendChild(script);
        });
    }

    async detect(imageData, frameId, captureTs) {
        const startTime = Date.now();

        if (!this.isLoaded) {
            // Return enhanced mock detection for demo purposes
            return this.getEnhancedMockDetection(frameId, captureTs, startTime);
        }

        try {
            if (this.isDebug) {
                console.log('ðŸ” Processing frame:', frameId);
            }

            // Preprocess image
            const tensor = await this.preprocessImage(imageData);

            if (this.isDebug) {
                console.log('ðŸ–¼ï¸ Tensor shape:', tensor.dims);
            }

            // Run inference
            const inputName = this.session.inputNames[0];
            const results = await this.session.run({ [inputName]: tensor });

            // Get the first output
            const outputName = this.session.outputNames[0];
            const output = results[outputName];

            if (this.isDebug) {
                console.log('ðŸ“Š Output shape:', output.dims);
                console.log('ðŸ“Š Output sample:', output.data.slice(0, 10));
            }

            // Post-process results
            const detections = this.postprocessResults(output.data, output.dims);

            if (this.isDebug && detections.length > 0) {
                console.log('ðŸŽ¯ Found detections:', detections.length, detections);
            }

            return {
                frame_id: frameId,
                capture_ts: captureTs,
                recv_ts: startTime,
                inference_ts: Date.now(),
                detections: detections
            };

        } catch (error) {
            console.error('âŒ WASM inference failed:', error);
            return this.getEnhancedMockDetection(frameId, captureTs, startTime);
        }
    }

    async preprocessImage(imageData) {
        // Create canvas for image processing
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');

        // Set canvas size to model input size
        canvas.width = this.inputSize;
        canvas.height = this.inputSize;

        // Create image element
        const img = new Image();
        img.src = imageData;

        return new Promise((resolve) => {
            img.onload = () => {
                // Draw image to canvas with resize
                ctx.drawImage(img, 0, 0, this.inputSize, this.inputSize);

                // Get image data
                const imageData = ctx.getImageData(0, 0, this.inputSize, this.inputSize);
                const data = imageData.data;

                // Convert to RGB and normalize [0-1]
                const input = new Float32Array(3 * this.inputSize * this.inputSize);

                // CHW format (Channel, Height, Width)
                for (let y = 0; y < this.inputSize; y++) {
                    for (let x = 0; x < this.inputSize; x++) {
                        const idx = (y * this.inputSize + x) * 4; // RGBA index
                        const chw_idx = y * this.inputSize + x;   // CHW index
                        
                        input[chw_idx] = data[idx] / 255.0;     // R channel
                        input[chw_idx + this.inputSize * this.inputSize] = data[idx + 1] / 255.0; // G channel
                        input[chw_idx + 2 * this.inputSize * this.inputSize] = data[idx + 2] / 255.0; // B channel
                    }
                }

                // Create tensor
                const tensor = new ort.Tensor('float32', input, [1, 3, this.inputSize, this.inputSize]);
                resolve(tensor);
            };
        });
    }

    postprocessResults(output, dims) {
        const detections = [];
        
        if (this.isDebug) {
            console.log('ðŸ“Š Processing output with dims:', dims);
        }

        // Handle different YOLOv5 output formats
        let numDetections, numFeatures;
        
        if (dims.length === 3) {
            // Format: [1, 25200, 85] - typical YOLOv5 output
            [, numDetections, numFeatures] = dims;
        } else if (dims.length === 2) {
            // Format: [25200, 85] - some models
            [numDetections, numFeatures] = dims;
        } else {
            console.warn('âš ï¸ Unexpected output dimensions:', dims);
            return [];
        }

        if (this.isDebug) {
            console.log(`ðŸ“Š Processing ${numDetections} detections with ${numFeatures} features each`);
        }

        for (let i = 0; i < numDetections; i++) {
            const offset = i * numFeatures;

            // Extract box coordinates (center format)
            const centerX = output[offset];
            const centerY = output[offset + 1];
            const width = output[offset + 2];
            const height = output[offset + 3];
            const confidence = output[offset + 4];

            // Skip low confidence detections early
            if (confidence < 0.25) continue;

            // Find best class (skip first 5 elements: x, y, w, h, conf)
            let bestClass = 0;
            let bestScore = 0;

            for (let j = 5; j < numFeatures; j++) {
                const classScore = output[offset + j];
                if (classScore > bestScore) {
                    bestScore = classScore;
                    bestClass = j - 5;
                }
            }

            // Final confidence is objectness * class confidence
            const finalScore = confidence * bestScore;

            // Skip low final scores
            if (finalScore < 0.5) continue;

            // Convert from center format to corner format and normalize [0-1]
            const xmin = Math.max(0, (centerX - width / 2) / this.inputSize);
            const ymin = Math.max(0, (centerY - height / 2) / this.inputSize);
            const xmax = Math.min(1, (centerX + width / 2) / this.inputSize);
            const ymax = Math.min(1, (centerY + height / 2) / this.inputSize);

            // Ensure valid box dimensions
            if (xmax > xmin && ymax > ymin) {
                detections.push({
                    label: this.classes[bestClass] || 'object',
                    score: finalScore,
                    xmin: xmin,
                    ymin: ymin,
                    xmax: xmax,
                    ymax: ymax
                });
            }
        }

        if (this.isDebug) {
            console.log(`ðŸŽ¯ Found ${detections.length} valid detections before NMS`);
        }

        // Apply Non-Maximum Suppression
        const finalDetections = this.applyNMS(detections, 0.4);
        
        if (this.isDebug && finalDetections.length > 0) {
            console.log(`âœ… Final detections after NMS:`, finalDetections);
        }

        return finalDetections;
    }

    applyNMS(detections, iouThreshold) {
        // Sort by confidence
        detections.sort((a, b) => b.score - a.score);

        const keep = [];

        for (let i = 0; i < detections.length; i++) {
            const current = detections[i];
            let shouldKeep = true;

            for (const kept of keep) {
                const iou = this.calculateIoU(current, kept);
                if (iou > iouThreshold) {
                    shouldKeep = false;
                    break;
                }
            }

            if (shouldKeep) {
                keep.push(current);
            }
        }

        return keep;
    }

    calculateIoU(box1, box2) {
        const x1 = Math.max(box1.xmin, box2.xmin);
        const y1 = Math.max(box1.ymin, box2.ymin);
        const x2 = Math.min(box1.xmax, box2.xmax);
        const y2 = Math.min(box1.ymax, box2.ymax);

        if (x2 <= x1 || y2 <= y1) return 0;

        const intersection = (x2 - x1) * (y2 - y1);
        const area1 = (box1.xmax - box1.xmin) * (box1.ymax - box1.ymin);
        const area2 = (box2.xmax - box2.xmin) * (box2.ymax - box2.ymin);
        const union = area1 + area2 - intersection;

        return intersection / union;
    }

    getEnhancedMockDetection(frameId, captureTs, startTime) {
        // Enhanced mock detection that simulates realistic object detection
        const mockObjects = [
            { label: 'person', score: 0.85, xmin: 0.1, ymin: 0.1, xmax: 0.3, ymax: 0.6 },
            { label: 'chair', score: 0.72, xmin: 0.5, ymin: 0.4, xmax: 0.8, ymax: 0.9 },
            { label: 'bottle', score: 0.68, xmin: 0.7, ymin: 0.1, xmax: 0.85, ymax: 0.4 },
            { label: 'laptop', score: 0.74, xmin: 0.2, ymin: 0.5, xmax: 0.6, ymax: 0.8 },
            { label: 'cell phone', score: 0.81, xmin: 0.6, ymin: 0.2, xmax: 0.75, ymax: 0.4 }
        ];

        // Randomly show 1-3 objects for realistic demo
        const numObjects = Math.floor(Math.random() * 3) + 1;
        const selectedObjects = [];
        
        for (let i = 0; i < numObjects; i++) {
            const randomIndex = Math.floor(Math.random() * mockObjects.length);
            selectedObjects.push(mockObjects[randomIndex]);
        }

        // Add some randomness to positions and scores
        const detections = selectedObjects.map(obj => ({
            ...obj,
            score: obj.score + (Math.random() - 0.5) * 0.1, // Â±5% score variation
            xmin: Math.max(0, obj.xmin + (Math.random() - 0.5) * 0.1),
            ymin: Math.max(0, obj.ymin + (Math.random() - 0.5) * 0.1),
            xmax: Math.min(1, obj.xmax + (Math.random() - 0.5) * 0.1),
            ymax: Math.min(1, obj.ymax + (Math.random() - 0.5) * 0.1)
        }));

        if (this.isDebug && detections.length > 0) {
            console.log('ðŸŽ­ Mock detections:', detections);
        }

        return {
            frame_id: frameId,
            capture_ts: captureTs,
            recv_ts: startTime,
            inference_ts: Date.now(),
            detections: detections
        };
    }
}

// Export for use in main app
window.WASMInference = WASMInference;